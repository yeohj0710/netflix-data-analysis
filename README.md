# 넷플릭스 데이터 분석 과제

## 1. 데이터 분석 및 EDA 수행

EDA(탐색적 데이터 분석)를 통해 데이터를 탐색한 결과, 다음과 같은 사실을 확인했습니다:

- **기술 통계**: 넷플릭스 데이터셋에서 개봉 연도(`release_year`), 작품 길이(`duration_numeric`), 작품 타입(`type`)과 같은 주요 변수들의 기본 통계를 확인했습니다. 예를 들어, 개봉 연도의 평균은 약 **2014년**이며, 가장 오래된 작품은 **1925년**에 개봉되었습니다.

- **변수 시각화**: 개봉 연도의 분포를 시각화한 결과, **2020년대**에 접어들며 넷플릭스에서 더 많은 작품들이 출시된 것을 알 수 있었습니다. 상위 10개의 장르에 속하는 작품 수를 시각화한 결과, **Dramas**, **Documentaries**, **Stand-Up Comedy**가 가장 많은 작품 수를 차지하고 있었습니다.

- **상관관계 분석**: 개봉 연도(`release_year`)와 작품 길이(`duration_numeric`) 간의 상관관계 분석을 수행한 결과, 두 변수 간 상관관계는 **-0.25**로 낮게 나타났습니다. 즉, 개봉 연도가 작품 길이와 큰 관련이 없음을 알 수 있었습니다.

## 2. 분석 방법 선택 이유

EDA를 통해 **시청 등급(`rating`)**을 예측하는 것이 적합한 문제로 판단했습니다. 작품의 타입(`type`), 개봉 연도(`release_year`), 작품 길이(`duration_numeric`)를 기반으로 시청 등급을 분류하는 모델을 구현하기로 결정했습니다.

**RandomForestClassifier**를 선택한 이유는 다음과 같습니다:

- **다양한 변수 처리**: RandomForest는 범주형 데이터와 연속형 데이터를 모두 처리할 수 있어, 작품의 타입, 개봉 연도와 같은 다양한 데이터를 잘 반영할 수 있습니다.
- **과적합 방지**: 여러 개의 의사결정 나무를 결합해 예측 성능을 높이고, 과적합 문제를 방지하는 특성이 있습니다.
- **비선형성 처리**: RandomForest는 데이터 간 비선형 관계를 잘 처리하여 복잡한 문제에 적합합니다.
- **다른 모델들이 부적합한 이유는 다음과 같습니다.**
  - **의사결정 나무**: 과적합 위험이 높습니다.
  - **로지스틱 회귀**: 비선형 관계를 처리하기 어렵습니다.
  - **KNN**: 데이터셋이 크면 학습 속도가 느리고 성능이 저하됩니다.
  - **SVM**: 대규모 데이터셋에서 학습 시간이 길고 메모리 사용량이 큽니다.

## 3. 모델 구현 및 학습

- **사용된 모델**: `RandomForestClassifier`를 사용했습니다. 이 모델은 여러 개의 의사결정 나무를 결합해 예측 성능을 높입니다.
- **데이터 분리**: 전체 데이터셋의 75%를 학습용으로, 나머지 25%를 테스트용으로 사용했습니다. 또한, 클래스 비율을 유지하기 위해 `stratify` 옵션을 사용했습니다.
- **데이터 전처리**: 범주형 변수는 `LabelEncoder`로 각각 숫자형으로 변환하였고, 결측치는 모두 제거했습니다. 또한, 데이터 불균형 문제를 해결하기 위해 데이터 수가 적은 시청 등급을 제거했습니다.

## 4. 모델 평가 및 성능 분석

참고사항: 모델 실행 시 결과 변동 여부

- **RandomForestClassifier**는 결정 나무의 개수를 증가시켜 예측 성능을 높이는 모델입니다. 이때, `random_state`를 지정하지 않으면 매번 다른 결과가 얻어집니다. 결과를 구체적인 수치를 가지고 설명하기 위해, 본 과제에서는 예시를 들어 `random_state=42`를 사용했을 때의 결과를 기반으로 설명하겠습니다.

모델 평가 결과는 다음과 같습니다.

- **Confusion Matrix**:

  - Confusion Matrix를 통해 예측된 시청 등급과 실제 등급을 비교한 결과, `TV-MA` 등급과 `TV-14` 등급에서 비교적 예측 성능이 괜찮았으나, `NC-17`, `UR` 등의 등급에서는 거의 예측하지 못했습니다.
  - 실제로 **TV-MA** 등급은 3207건 중 다수가 올바르게 예측된 반면, **NC-17** 등급과 같은 드문 등급은 정확한 예측이 거의 불가능했습니다.

- **Accuracy**:

  - 전체 데이터에 대한 정확도는 **38.3%**로, 모델이 38.3%의 정확도로 시청 등급을 예측했습니다.

- **Precision**:

  - Precision(정밀도)은 **34.2%**로, 모델이 예측한 시청 등급 중 실제 등급이 맞은 비율이 34.2%였습니다.

- **Recall**:

  - Recall(재현율)은 **38.3%**로, 실제 등급 중 모델이 올바르게 예측한 비율을 나타냅니다.

- **F1-Score**:

  - Precision과 Recall의 균형을 맞춘 F1-Score는 **34.9%**입니다.

## 5. 결과 분석

모델의 성능을 바탕으로 다음과 같은 분석을 수행했습니다:

1. **데이터 불균형**: 일부 시청 등급에서 데이터가 불균형하게 분포되어 있었으며, 그로 인해 특정 등급에 대한 예측 정확도가 낮아졌습니다. 예를 들어, **TV-MA** 등급은 **3207건**으로 매우 많은 데이터를 가지고 있었지만, **NC-17** 등급과 **UR** 등급은 각각 **3건**에 불과했습니다. 이러한 데이터 불균형으로 인해 드문 등급에 대한 예측이 어려웠습니다.

2. **변수의 영향 분석**: 데이터 불균형을 해결하고 나서도, 모델은 `release_year`와 `type`, `duration_numeric`에 주로 의존하여 예측을 수행했습니다. 이는 개봉 연도와 작품 타입, 작품 길이가 시청 등급에 중요한 역할을 할 수 있음을 시사합니다.

3. **모델의 성능 개선 방안**: 모델의 전반적인 성능(Accuracy: 38.3%)은 다소 낮은 수준입니다. 이는 시청 등급이 단순히 개봉 연도나 작품 길이로만 결정되지 않기 때문일 수 있습니다. 작품의 주제, 제작국가, 감독이나 배우 등 더 다양한 변수를 고려하면 예측 성능이 개선될 가능성이 있습니다.
